{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%d/%m/%Y')\n",
    "\n",
    "ally = pd.read_csv('data/ally.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "axp = pd.read_csv('data/axp.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bac = pd.read_csv('data/bac.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bbt = pd.read_csv('data/bbt.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bbva = pd.read_csv('data/bbva.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bcs = pd.read_csv('data/bcs.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bk = pd.read_csv('data/bk.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "bku = pd.read_csv('data/bku.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "cfg = pd.read_csv('data/cfg.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "citi = pd.read_csv('data/citi.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "cof = pd.read_csv('data/cof.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "dfs = pd.read_csv('data/dfs.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "fbp = pd.read_csv('data/fbp.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "fmbi = pd.read_csv('data/fmbi.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "gs = pd.read_csv('data/gs.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "hsbc = pd.read_csv('data/hsbc.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "jpm = pd.read_csv('data/jpm.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "ms = pd.read_csv('data/ms.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "pnc = pd.read_csv('data/pnc.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "schw = pd.read_csv('data/schw.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "snv = pd.read_csv('data/snv.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "sti = pd.read_csv('data/sti.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "stt = pd.read_csv('data/stt.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "td = pd.read_csv('data/td.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "usb = pd.read_csv('data/usb.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)\n",
    "wfc = pd.read_csv('data/wfc.csv', index_col=\"Date\", usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"Rate\"],\n",
    "        parse_dates=[\"Date\"], date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [ally, axp, bac, bbt,bbva,bcs,bk,bku,cfg,citi,cof,dfs,fbp,fmbi,gs,hsbc,jpm,ms,pnc,schw,snv,sti,stt,td,usb,wfc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ds:\n",
    "    i['Rate'] = i['Rate'].map({'C':21,'Ca':20,'Caa3':19,'Caa2':18,'Caa1':17,'B3':16,'B2':15,'B1':14,'Ba3':13,'Ba2':12,'Ba1':11,'Baa3':10,'Baa2':9,'Baa1':8,'A3':7,'A2':6,'A1':5,'Aa3':14,'Aa2':3,'Aa1':2,'Aaa':1})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ds:\n",
    "    temp = i['Rate'].unique()\n",
    "    temp_rep = [0]\n",
    "    for j in range(1,len(temp)):\n",
    "        if temp[j] > temp[j-1]:\n",
    "            temp_rep.append(-1)\n",
    "        if temp[j] < temp[j-1]:\n",
    "            temp_rep.append(1)\n",
    "        if temp[j] == temp[j-1]:\n",
    "            temp_rep.append(0)\n",
    "    for r in range(0,len(temp)):\n",
    "        i['Rate'].replace(temp[r],temp_rep[r],inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[ 0 -1]\n",
      "[ 0  1 -1]\n",
      "[ 0  1 -1]\n",
      "[ 0 -1  1]\n",
      "[ 0 -1  1]\n",
      "[ 0 -1  1]\n",
      "[ 0 -1]\n",
      "[ 0 -1]\n",
      "[ 0 -1  1]\n",
      "[0 1]\n",
      "[ 0 -1]\n",
      "[ 0 -1  1]\n",
      "[ 0  1 -1]\n",
      "[ 0 -1  1]\n",
      "[ 0 -1  1]\n",
      "[ 0  1 -1]\n",
      "[ 0  1 -1]\n",
      "[ 0  1 -1]\n",
      "[0 1]\n",
      "[ 0  1 -1]\n",
      "[ 0 -1  1]\n",
      "[ 0 -1  1]\n",
      "[ 0  1 -1]\n",
      "[ 0  1 -1]\n",
      "[ 0  1 -1]\n"
     ]
    }
   ],
   "source": [
    "for i in ds:\n",
    "    print(i['Rate'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-06-20</th>\n",
       "      <td>15.583333</td>\n",
       "      <td>16.041666</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>6.621490</td>\n",
       "      <td>3337500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-21</th>\n",
       "      <td>16.083334</td>\n",
       "      <td>16.166666</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>15.958333</td>\n",
       "      <td>6.656251</td>\n",
       "      <td>3398400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-22</th>\n",
       "      <td>15.958333</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>6.725768</td>\n",
       "      <td>2190300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-23</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.083334</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>6.638872</td>\n",
       "      <td>1453800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-26</th>\n",
       "      <td>15.833333</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>15.791667</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>6.604112</td>\n",
       "      <td>2271600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close   Volume  \\\n",
       "Date                                                                         \n",
       "1995-06-20  15.583333  16.041666  15.500000  15.875000   6.621490  3337500   \n",
       "1995-06-21  16.083334  16.166666  15.833333  15.958333   6.656251  3398400   \n",
       "1995-06-22  15.958333  16.250000  15.916667  16.125000   6.725768  2190300   \n",
       "1995-06-23  16.000000  16.083334  15.750000  15.916667   6.638872  1453800   \n",
       "1995-06-26  15.833333  15.916667  15.791667  15.833333   6.604112  2271600   \n",
       "\n",
       "            Rate  \n",
       "Date              \n",
       "1995-06-20     0  \n",
       "1995-06-21     0  \n",
       "1995-06-22     0  \n",
       "1995-06-23     0  \n",
       "1995-06-26     0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4496, 30, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "samples_b = list()\n",
    "for b in range(0,len(ds)):\n",
    "    #Split into samples \n",
    "    samples = list()\n",
    "    length = 30\n",
    "    # step over the length of each bank in jumps of 30\n",
    "    for i in range(0,len(ds[b])-len(ds[b])%length,length):\n",
    "        # grab from i to i + 30\n",
    "        sample = ds[b][i:i+length]\n",
    "        samples.append(sample)\n",
    "    for j in range(0,len(samples)):\n",
    "        samples[j] = array(samples[j])\n",
    "        #Scaled values\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        samples[j] = scaler.fit_transform(samples[j])\n",
    "        samples[j] = samples[j].reshape(1,length,7)\n",
    "    data = np.concatenate((samples))\n",
    "    samples_b.append((data))\n",
    "\n",
    "data = np.concatenate(samples_b)\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3147, 30, 6) (3147, 30) (1348, 30, 6) (1348, 30)\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "ratio = np.array([0.7,0.3])\n",
    "ratio = (ratio*N).astype(np.int32)\n",
    "\n",
    "ind = np.random.permutation(N)\n",
    "\n",
    "train = data[ind[:ratio[0]], :]\n",
    "test = data[ind[:ratio[1]], :]\n",
    "# split into input and outputs\n",
    "X_train, y_train = train[:, :, :-1], train[:, :, -1]\n",
    "X_test, y_test = test[:, :, :-1], test[:, :, -1]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-cf9b78be2aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (1,) but got array with shape (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-248887d50424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# plot history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (1,) but got array with shape (30,)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=8)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
